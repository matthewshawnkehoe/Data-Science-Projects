{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "We start by loading the *MNIST* dataset using the `mnist` class from the `keras.datasets` module. We will later build our model using the `Sequential()` class of the `keras.models` module. To do this, we will add dense layers to our `model` object."
      ],
      "metadata": {
        "id": "ZMQCk--z-qeJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4O0Xha-z-fwK"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now work on a famous optical character recognition dataset called *MNIST*. This dataset consists of 70,000 grayscale images of handwritten digits. In the following, we'll load the dataset and do some data preprocessing. As we'll see, each image is represented as 28x28 pixel data. This is a two-dimensional vector. We'll convert this to a vector of length 784, which will be single-dimensional. We'll also normalize each vector by dividing each element by 255 (which is the maximum value of the RGB color scale)."
      ],
      "metadata": {
        "id": "4ly74gAV_bAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "input_dim = 784  # 28*28\n",
        "output_dim = nb_classes = 10\n",
        "batch_size = 128\n",
        "nb_epoch = 20\n",
        "\n",
        "X_train = X_train.reshape(60000, input_dim)\n",
        "X_test = X_test.reshape(10000, input_dim)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAS609Jl_bf8",
        "outputId": "dd06504a-4cbf-4b87-ca53-24896d719b48"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll *one-hot code* our *target variable* using the `to_categorical()` function from the `keras.utils` module:"
      ],
      "metadata": {
        "id": "lDdtCaXp_yWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train = to_categorical(y_train, nb_classes)\n",
        "Y_test = to_categorical(y_test, nb_classes)"
      ],
      "metadata": {
        "id": "jAmTuk6P_ziy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q1. Build an ANN and train and test it using the MNIST data. This ANN should consist of two hidden layers and one output layer. All of the hidden layers should be dense. The first layer and the second layer should have neuron sizes of 32 and 16, respectively. Train this model for 20 epochs, and compare our training and test set performance with the previous parameters. Is there any difference? If so, why?"
      ],
      "metadata": {
        "id": "EgGM7jtiAD80"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will create two dense layers of size 32 and 16. The third layer will contain a `softmax` activation function which computes the probability of being in one of the ten different number classes."
      ],
      "metadata": {
        "id": "hSe4p6pcAQ64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "# The first dense layer\n",
        "model.add(Dense(32, input_shape=(784,), activation=\"relu\"))\n",
        "# The second dense layer\n",
        "model.add(Dense(16, activation=\"relu\"))\n",
        "# The last layer is the output layer\n",
        "model.add(Dense(10, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "TCoEAVIzALUn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can summarize our dense layers:"
      ],
      "metadata": {
        "id": "e5z2ckIBAr5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxJw10AfAtq6",
        "outputId": "eb4189e1-602c-429e-da6b-d44d3e53606c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 32)                25120     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                170       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25818 (100.85 KB)\n",
            "Trainable params: 25818 (100.85 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we will compile our model."
      ],
      "metadata": {
        "id": "dVIXnROPA1k8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "NQQeKgpdA3sX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then train our model for 20 epochs."
      ],
      "metadata": {
        "id": "q6Svfe-XA9fL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting `verbose=1` prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_U2---PxA-7z",
        "outputId": "06ea34ea-1fe7-4f11-f74c-3d27d6570b54"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 1.5803 - accuracy: 0.5476\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.6653 - accuracy: 0.8269\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4648 - accuracy: 0.8715\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3911 - accuracy: 0.8905\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3523 - accuracy: 0.9003\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3267 - accuracy: 0.9068\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3075 - accuracy: 0.9120\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2920 - accuracy: 0.9168\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2788 - accuracy: 0.9207\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2676 - accuracy: 0.9239\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2575 - accuracy: 0.9266\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.2484 - accuracy: 0.9296\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2401 - accuracy: 0.9316\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.2330 - accuracy: 0.9339\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2259 - accuracy: 0.9362\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2200 - accuracy: 0.9372\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2141 - accuracy: 0.9390\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2089 - accuracy: 0.9405\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2035 - accuracy: 0.9419\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1989 - accuracy: 0.9433\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d7e75a361d0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that our model got to slightly below 95% accuracy. With two dense layers of neuron size 128, it achieved about 97% accuracy. As a final step, we will evaluate our model on the test set."
      ],
      "metadata": {
        "id": "rDe4MYBDBNwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hT3sWIqcBiox",
        "outputId": "44f98c02-e83a-4390-d6dc-ddbfede54c31"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test score: 0.20107264816761017\n",
            "Test accuracy: 0.9416999816894531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model achieved about 94% accuracy in both the training and the test set. This is worse peformance than our previous model with two dense layers and 1028 neurons. As the layers include less number of neurons, the model is simpler than the one previously and cannot learn complex relationships between spatial features in the input data. This resulted in a lower performance. It seems, MNIST data requires more neurons in the intermediate layers."
      ],
      "metadata": {
        "id": "yhBv0DqPBrLN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2. In this task, build another ANN. This ANN should have five hidden layers and one output layer. All of the layers should be dense. The neuron numbers for the hidden layers should be 1024, 512, 256, 128, and 64. Train this model for 20 epochs, and test it using the same data from the previous task. Then compare the results. Is there any difference? If so, why?"
      ],
      "metadata": {
        "id": "bp6BCQsICAQX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we will create five dense layers of size 1024, 512, 256, 128, and 64. The sixth layer will contain a softmax activation function which computes the probability of being in one of the ten different number classes."
      ],
      "metadata": {
        "id": "-pH3sUz5CMJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "# The first dense layer\n",
        "model.add(Dense(1024, input_shape=(784,), activation=\"relu\"))\n",
        "# The second dense layer\n",
        "model.add(Dense(512, activation=\"relu\"))\n",
        "# The third dense layer\n",
        "model.add(Dense(256, activation=\"relu\"))\n",
        "# The fourth dense layer\n",
        "model.add(Dense(128, activation=\"relu\"))\n",
        "# The fifth dense layer\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "# The last layer is the output layer\n",
        "model.add(Dense(10, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "eTjvdMamB_lN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can summarize our dense layers:"
      ],
      "metadata": {
        "id": "EMZIYsZbCkc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YACU4vGtCkvA",
        "outputId": "9fedf3fa-0206-4ba4-be93-81325d26466e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 1024)              803840    \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1501770 (5.73 MB)\n",
            "Trainable params: 1501770 (5.73 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As before, we will compile our model."
      ],
      "metadata": {
        "id": "IW80wpDKD2mx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "liEfoKlmD5P4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then train our model for 20 epochs."
      ],
      "metadata": {
        "id": "Np-y5fl1D9Vw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQIcH3SxD9tl",
        "outputId": "d27845e2-e9b7-4968-9c22-3101a4ad852f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 18s 37ms/step - loss: 1.2654 - accuracy: 0.6827\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 14s 31ms/step - loss: 0.3633 - accuracy: 0.8973\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 15s 32ms/step - loss: 0.2744 - accuracy: 0.9205\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 15s 32ms/step - loss: 0.2295 - accuracy: 0.9344\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 14s 31ms/step - loss: 0.1984 - accuracy: 0.9431\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 15s 31ms/step - loss: 0.1756 - accuracy: 0.9498\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 15s 31ms/step - loss: 0.1572 - accuracy: 0.9546\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 14s 31ms/step - loss: 0.1416 - accuracy: 0.9592\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 14s 31ms/step - loss: 0.1282 - accuracy: 0.9633\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 15s 31ms/step - loss: 0.1172 - accuracy: 0.9664\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 15s 31ms/step - loss: 0.1069 - accuracy: 0.9700\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 14s 30ms/step - loss: 0.0984 - accuracy: 0.9722\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 14s 30ms/step - loss: 0.0903 - accuracy: 0.9740\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 14s 30ms/step - loss: 0.0834 - accuracy: 0.9765\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.0767 - accuracy: 0.9783\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 14s 31ms/step - loss: 0.0714 - accuracy: 0.9802\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 15s 32ms/step - loss: 0.0661 - accuracy: 0.9818\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 14s 30ms/step - loss: 0.0612 - accuracy: 0.9830\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 14s 30ms/step - loss: 0.0566 - accuracy: 0.9845\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 14s 30ms/step - loss: 0.0530 - accuracy: 0.9859\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d7e58e58220>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that our model got to slightly below 99% accuracy. With five dense layers of neuron size 1024, 512, 256, 128, and 64, it achieved about 99% accuracy. As a final step, we will evaluate our model on the test set."
      ],
      "metadata": {
        "id": "eMzrFVXxEbeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XupOd4ebEkpt",
        "outputId": "1aebf421-a830-46fa-a61a-d407db824bf4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test score: 0.08893519639968872\n",
            "Test accuracy: 0.9728999733924866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, the model achieved almost 99% accuracy in the training set and 98% accuracy in the test set. The model here is more complex than the model of the previous task and the model previously. Because this model contains more neurons it the intermediate layers, it achieved higher performance in the training set. The additional intermediate dense layers allowed this model to learn complex relationships between spatial features. However, the difference between the training score and test score widened a little bit. It may be a sign that this model has started to overfit."
      ],
      "metadata": {
        "id": "gLv5r0FqEs9R"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5ITRRgUMFBr0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}