{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create a travel app in Dash. We first load the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dash in c:\\users\\mskeh\\anaconda3\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: Flask<3.1,>=1.0.4 in c:\\users\\mskeh\\anaconda3\\lib\\site-packages (from dash) (2.2.2)\n",
      "Requirement already satisfied: Werkzeug<3.1 in c:\\users\\mskeh\\anaconda3\\lib\\site-packages (from dash) (2.2.3)\n",
      "Requirement already satisfied: plotly>=5.0.0 in c:\\users\\mskeh\\anaconda3\\lib\\site-packages (from dash) (5.9.0)\n",
      "Requirement already satisfied: dash-html-components==2.0.0 in c:\\users\\mskeh\\anaconda3\\lib\\site-packages (from dash) (2.0.0)\n",
      "Requirement already satisfied: dash-core-components==2.0.0 in c:\\users\\mskeh\\anaconda3\\lib\\site-packages (from dash) (2.0.0)\n",
      "Requirement already satisfied: dash-table==5.0.0 in c:\\users\\mskeh\\anaconda3\\lib\\site-packages (from dash) (5.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\mskeh\\anaconda3\\lib\\site-packages (from dash) (4.7.1)\n",
      "Requirement already satisfied: requests in c:\\users\\mskeh\\anaconda3\\lib\\site-packages (from dash) (2.31.0)\n",
      "Requirement already satisfied: retrying in c:\\users\\mskeh\\anaconda3\\lib\\site-packages (from dash) (1.3.4)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\mskeh\\anaconda3\\lib\\site-packages (from dash) (1.5.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mskeh\\anaconda3\\lib\\site-packages (from dash) (68.0.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\mskeh\\anaconda3\\lib\\site-packages (from dash) (6.0.0)\n",
      "Requirement already satisfied: Jinja2>=3.0 in c:\\users\\mskeh\\anaconda3\\lib\\site-packages (from Flask<3.1,>=1.0.4->dash) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in c:\\users\\mskeh\\anaconda3\\lib\\site-packages (from Flask<3.1,>=1.0.4->dash) (2.0.1)\n",
      "Requirement already satisfied: click>=8.0 in c:\\users\\mskeh\\anaconda3\\lib\\site-packages (from Flask<3.1,>=1.0.4->dash) (8.0.4)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\mskeh\\anaconda3\\lib\\site-packages (from plotly>=5.0.0->dash) (8.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\mskeh\\anaconda3\\lib\\site-packages (from Werkzeug<3.1->dash) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\mskeh\\anaconda3\\lib\\site-packages (from importlib-metadata->dash) (3.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mskeh\\anaconda3\\lib\\site-packages (from requests->dash) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mskeh\\anaconda3\\lib\\site-packages (from requests->dash) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mskeh\\anaconda3\\lib\\site-packages (from requests->dash) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mskeh\\anaconda3\\lib\\site-packages (from requests->dash) (2023.11.17)\n",
      "Requirement already satisfied: six>=1.7.0 in c:\\users\\mskeh\\anaconda3\\lib\\site-packages (from retrying->dash) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mskeh\\anaconda3\\lib\\site-packages (from click>=8.0->Flask<3.1,>=1.0.4->dash) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "W8lVwRl18vRp"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mskeh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mskeh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import datetime\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download stopwords from nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Download the WordNet resource\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "# Import necessary Dash components\n",
    "from dash import dcc, html, Dash\n",
    "from dash.dependencies import Input, Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then preprocess the text and split our dataset into Train and Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QFkg_NxK-os2"
   },
   "outputs": [],
   "source": [
    "travel_df = pd.read_csv('C:/Users/mskeh/Documents/GitHub/Thinkful/Capstone Projects/Final_Capstone_NLP_Search_Recommendation/Data/all_things_to_do.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_column(df, column_name):\n",
    "    \"\"\"\n",
    "    Clean the specified text column in the DataFrame using NLTK for tokenization,\n",
    "    stopword removal, lemmatization, and punctuation removal.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): DataFrame containing the text column.\n",
    "    - column_name (str): Name of the text column to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Ensure the specified column exists in the DataFrame\n",
    "    if column_name not in df.columns:\n",
    "        print(f\"Column '{column_name}' not found in the DataFrame.\")\n",
    "        return\n",
    "\n",
    "    # Define NLTK objects for stop words and lemmatization\n",
    "    stop_words_ = set(stopwords.words('english'))\n",
    "    wn = WordNetLemmatizer()\n",
    "\n",
    "    def black_txt(token):\n",
    "        # Check if the token is not a stop word, not a punctuation, and has a length greater than 2\n",
    "        return token not in stop_words_ and token not in list(string.punctuation) and len(token) > 2\n",
    "\n",
    "    def clean_txt(text):\n",
    "        # Remove apostrophes, digits, non-word characters, and replace 'nbsp'\n",
    "        text = re.sub(\"'\", \"\", text)\n",
    "        text = re.sub(\"(\\\\d|\\\\W)+\", \" \", text)\n",
    "        text = text.replace(\"nbsp\", \"\")\n",
    "\n",
    "        # Tokenize, lemmatize, and filter based on defined conditions\n",
    "        clean_text = [wn.lemmatize(word, pos=\"v\") for word in word_tokenize(text.lower()) if black_txt(word)]\n",
    "\n",
    "        return \" \".join(clean_text)\n",
    "\n",
    "    # Apply the cleaning function to the specified column\n",
    "    df[column_name] = df[column_name].apply(clean_txt)\n",
    "\n",
    "# Apply the clean text function to the \"Things to Do\"\n",
    "clean_text_column(travel_df, 'Text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ComplementNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ComplementNB</label><div class=\"sk-toggleable__content\"><pre>ComplementNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ComplementNB()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = travel_df['Text']\n",
    "y = travel_df['Location']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer='word', decode_error='ignore', ngram_range=(1,2))\n",
    "X_train_baseline = vectorizer.fit_transform(X_train)\n",
    "\n",
    "model = ComplementNB()\n",
    "model.fit(X_train_baseline, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's construct our Dash app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dash.default_mode = \"jupyterlab\"\n",
    "\n",
    "def get_prediction(text):\n",
    "    try:\n",
    "        probas = model.predict_proba(vectorizer.transform([text]))\n",
    "        classes = model.classes_\n",
    "        top_pred = classes[probas.argmax()]\n",
    "        return top_pred\n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_app_layout():\n",
    "    \"\"\"\n",
    "    Create the layout for the Dash app.\n",
    "\n",
    "    Returns:\n",
    "    - layout: Dash HTML component\n",
    "        The layout for the Dash app.\n",
    "    \"\"\"\n",
    "    return html.Div(children=[\n",
    "        html.H1(children='Wanderlust Wizard - Your Travel Advisor Companion', style={'textAlign': 'center', 'margin-top': '5%', 'color': '#3366cc'}),\n",
    "        html.H4(children='Craft your dream journey by sharing your ideal vacation activities.', style={'textAlign': 'center', 'color': '#3366cc'}),\n",
    "        html.Br(),\n",
    "        html.Div([\n",
    "            \"What's your dream vacation activity? Tell us, and let's create your perfect adventure:  \",\n",
    "            dcc.Input(id='my-input', value='', type='text',\n",
    "                      placeholder='e.g., Sailing under the Northern Lights', style={'width': '65%', 'color': '#3366cc'}),\n",
    "        ], style={'margin-left': '10%', 'margin-right': '10%'}),\n",
    "        html.Hr(),\n",
    "        html.H5(children='Your Personalized Travel Recommendation Awaits:', style={'textAlign': 'center', 'color': '#3366cc'}),\n",
    "        html.H4(id='my-output', style={'textAlign': 'center', 'color': '#3366cc'}),\n",
    "        html.Br(),\n",
    "        html.Hr(),\n",
    "        html.H5(children='Embark on a Journey of Discovery', style={'margin-left': '10%', 'margin-right': '10%', 'color': '#3366cc'}),\n",
    "        html.Div(children=\"Join us on a journey fueled by data from 50,000 attractions across 30 locations on Trip Advisor. Our cutting-edge Complement Naive Bayes algorithm ensures tailor-made suggestions for your dream adventure, making every exploration memorable.\",\n",
    "                 style={'margin-left': '10%', 'margin-right': '10%', 'color': '#3366cc'}),\n",
    "    ], style={'background-color': '#f2f2f2'})  # Set the default background color\n",
    "\n",
    "def run_travel_app():\n",
    "    \"\"\"\n",
    "    Run the Dash app for the travel recommendation system.\n",
    "    \"\"\"\n",
    "    # Initialize the Dash app\n",
    "    app = Dash(__name__)\n",
    "\n",
    "    # Set external stylesheets if needed\n",
    "    external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "    app = Dash(__name__, external_stylesheets=external_stylesheets)\n",
    "\n",
    "    # Set the app layout\n",
    "    app.layout = create_app_layout()\n",
    "\n",
    "    # Set the app callback\n",
    "    @app.callback(\n",
    "        Output(component_id='my-output', component_property='children'),\n",
    "        Input(component_id='my-input', component_property='value')\n",
    "    )\n",
    "    def update_output_div(input_value):\n",
    "        if not input_value:  # Check if input is empty\n",
    "            return \"Please enter some text to get a recommendation\"\n",
    "        \n",
    "        top_pred = get_prediction(input_value)\n",
    "        if top_pred is not None:\n",
    "            return f\"{top_pred}\"\n",
    "        else:\n",
    "            return \"Error during prediction\"\n",
    "\n",
    "    # Run the app\n",
    "    if __name__ == '__main__':\n",
    "        app.run_server(debug=True, mode='external', host='localhost')\n",
    "\n",
    "# Run the Dash app\n",
    "run_travel_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
